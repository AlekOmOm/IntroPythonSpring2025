# Data Science Tools: Key Terms and Analysis

## Key Terms List

### NumPy
1. **Array**
2. **Vectorization**
3. **Broadcasting**
4. **Universal Functions (ufuncs)**
5. **Indexing and Slicing**
6. **Reshaping**
7. **Aggregation Functions**
8. **Linear Algebra Operations**

### Matplotlib
1. **Figure**
2. **Axes**
3. **Plots**
4. **Subplots**
5. **Customization**
6. **Saving Figures**

### Statistical Analysis
1. **Mean**
2. **Variance**
3. **Correlation**
4. **Linear Regression**

---

## Term Analysis

### NumPy

#### 1. Array

**Definition:**
A NumPy array is a grid of values, all of the same type, indexed by a tuple of non-negative integers. The number of dimensions is the rank of the array, and the shape of an array is a tuple of integers giving the size of the array along each dimension.

**Explanation:**
NumPy arrays are the core data structure of the NumPy library. Unlike Python lists, NumPy arrays are homogeneous (all elements must be of the same type) and provide memory-efficient storage and faster operations. They enable vectorized operations, eliminating the need for explicit loops, which makes code more concise and typically runs much faster.

**Example:**
```python
import numpy as np

# Creating arrays
arr1 = np.array([1, 2, 3, 4, 5])                  # 1D array
arr2 = np.array([[1, 2, 3], [4, 5, 6]])           # 2D array
zeros = np.zeros((3, 4))                          # 3x4 array of zeros
ones = np.ones((2, 3, 4))                         # 3D array of ones
random_arr = np.random.random((2, 2))             # 2x2 array of random values
range_arr = np.arange(0, 10, 2)                   # [0, 2, 4, 6, 8]
linspace = np.linspace(0, 1, 5)                   # 5 evenly spaced values from 0 to 1

# In data analysis context
data_points = np.array([23.1, 24.5, 25.3, 24.8, 25.2, 26.1])  # Temperature readings
```

#### 2. Vectorization

**Definition:**
Vectorization refers to the process of applying operations to entire arrays without using explicit loops, enabling faster and more concise code.

**Explanation:**
Vectorization is a key concept in NumPy that allows mathematical operations to be applied to entire arrays at once, rather than iterating through each element. This approach leverages optimized, pre-compiled C code, making operations significantly faster than equivalent Python loops. Vectorization also makes code more readable and less prone to errors.

**Example:**
```python
import numpy as np
import time

# Non-vectorized approach (slow)
def traditional_approach(size):
    result = []
    for i in range(size):
        result.append(i ** 2)
    return result

# Vectorized approach (fast)
def vectorized_approach(size):
    return np.arange(size) ** 2

# Compare performance
size = 1000000
start = time.time()
traditional_result = traditional_approach(size)
traditional_time = time.time() - start

start = time.time()
vectorized_result = vectorized_approach(size)
vectorized_time = time.time() - start

print(f"Traditional time: {traditional_time:.6f} seconds")
print(f"Vectorized time: {vectorized_time:.6f} seconds")
print(f"Speedup: {traditional_time/vectorized_time:.2f}x")

# In data analysis context
temperatures = np.array([23.1, 24.5, 25.3, 24.8, 25.2, 26.1])
# Convert Celsius to Fahrenheit in one operation
fahrenheit = (temperatures * 9/5) + 32
```

#### 3. Broadcasting

**Definition:**
Broadcasting is a mechanism that allows NumPy to perform operations on arrays of different shapes, automatically expanding the smaller array to match the shape of the larger array.

**Explanation:**
Broadcasting eliminates the need to create unnecessary copies of data and makes array operations more memory-efficient. It follows specific rules to determine how arrays of different shapes can be combined. Understanding broadcasting is crucial for writing efficient NumPy code and avoiding common errors when working with arrays of different dimensions.

**Example:**
```python
import numpy as np

# Adding a scalar to an array
arr = np.array([1, 2, 3, 4, 5])
result = arr + 10  # [11, 12, 13, 14, 15]

# Adding a 1D array to a 2D array
data = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
row_adjustment = np.array([10, 20, 30])
# Each column gets adjusted by the corresponding value
adjusted_data = data + row_adjustment.reshape(3, 1)
print(adjusted_data)
# [[ 11  12  13]
#  [ 24  25  26]
#  [ 37  38  39]]

# In data analysis context
measurements = np.array([[25.1, 24.8, 25.0],  # Day 1 readings
                         [24.9, 25.2, 25.1],  # Day 2 readings
                         [25.3, 25.4, 25.2]]) # Day 3 readings
                         
# Apply calibration adjustment to each sensor
calibration_factors = np.array([0.2, -0.1, 0.3])  # Adjustments for each sensor
calibrated_data = measurements + calibration_factors  # Broadcasting in action
```

#### 4. Universal Functions (ufuncs)

**Definition:**
Universal functions (ufuncs) are NumPy functions that operate element-wise on arrays, supporting array broadcasting, type casting, and other features.

**Explanation:**
Ufuncs are vectorized wrappers for simple functions that take a fixed number of inputs and produce a fixed number of outputs. They're implemented in C, making them much faster than equivalent Python functions. Ufuncs are the backbone of NumPy's computational capabilities, providing fast mathematical, logical, and statistical operations on arrays.

**Example:**
```python
import numpy as np

# Mathematical ufuncs
arr = np.array([1, 2, 3, 4, 5])
sqrt_arr = np.sqrt(arr)  # [1., 1.41421356, 1.73205081, 2., 2.23606798]
exp_arr = np.exp(arr)    # [2.71828183, 7.3890561, 20.08553692, 54.59815003, 148.4131591]
log_arr = np.log(arr)    # [0., 0.69314718, 1.09861229, 1.38629436, 1.60943791]

# Trigonometric ufuncs
angles = np.array([0, np.pi/4, np.pi/2, np.pi])
sin_values = np.sin(angles)  # [0., 0.70710678, 1., 0.]
cos_values = np.cos(angles)  # [1., 0.70710678, 0., -1.]

# Logical ufuncs
a = np.array([1, 2, 3, 4])
b = np.array([4, 3, 2, 1])
greater = np.greater(a, b)       # [False, False, True, True]
equal = np.equal(a, b)           # [False, False, False, False]
logical_or = np.logical_or(a > 2, b > 2)  # [False, True, True, True]

# In data analysis context
sensor_readings = np.array([23.1, 24.5, 25.3, 24.8, 25.2, 26.1])
normalized = (sensor_readings - np.mean(sensor_readings)) / np.std(sensor_readings)
outliers = np.abs(normalized) > 2.0  # Boolean mask for values more than 2 std deviations away
```

#### 5. Indexing and Slicing

**Definition:**
Indexing and slicing in NumPy allow for selecting and manipulating specific elements, rows, columns, or subarrays from an array.

**Explanation:**
NumPy provides powerful indexing capabilities that extend Python's standard indexing and slicing. These include integer indexing, boolean indexing, fancy indexing (using arrays of indices), and more. Efficient indexing is crucial for data extraction, filtering, and manipulation in data analysis workflows.

**Example:**
```python
import numpy as np

# Create a 2D array
arr = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])

# Basic indexing
element = arr[1, 2]  # Value 7 (row 1, column 2)

# Slicing
row = arr[1, :]        # [5, 6, 7, 8] (entire row 1)
column = arr[:, 2]     # [3, 7, 11] (entire column 2)
subarray = arr[0:2, 1:3]  # [[2, 3], [6, 7]] (first 2 rows, columns 1 and 2)

# Boolean indexing
mask = arr > 6
filtered = arr[mask]  # [7, 8, 9, 10, 11, 12]

# Fancy indexing
rows = np.array([0, 2])
cols = np.array([1, 3])
selection = arr[rows[:, np.newaxis], cols]  # [[2, 4], [10, 12]]

# In data analysis context
temperatures = np.array([23.1, 24.5, 25.3, 24.8, 25.2, 26.1, 23.8, 25.9, 26.8])
high_temps = temperatures[temperatures > 25.0]  # Select only high temperatures
weekday_temps = temperatures[::7]  # Select temperatures on the same day each week
```

#### 6. Reshaping

**Definition:**
Reshaping is the process of changing the shape (dimensions) of an array without changing its data.

**Explanation:**
NumPy's reshaping capabilities allow you to reorganize the elements of an array into a new shape without changing the data itself. This is useful for transforming data between different representations, such as converting between 1D and 2D arrays or changing the layout of multidimensional data. Common reshaping operations include reshape, flatten, and transpose.

**Example:**
```python
import numpy as np

# Create a 1D array
arr = np.arange(12)  # [0, 1, 2, ..., 11]

# Reshape to 2D array (3 rows, 4 columns)
arr_2d = arr.reshape(3, 4)
print(arr_2d)
# [[ 0  1  2  3]
#  [ 4  5  6  7]
#  [ 8  9 10 11]]

# Reshape to 2D array (4 rows, 3 columns)
arr_2d_alt = arr.reshape(4, 3)
print(arr_2d_alt)
# [[ 0  1  2]
#  [ 3  4  5]
#  [ 6  7  8]
#  [ 9 10 11]]

# Reshape using -1 (automatically determine the dimension)
arr_2d_auto = arr.reshape(6, -1)  # 6 rows, 2 columns
print(arr_2d_auto)
# [[ 0  1]
#  [ 2  3]
#  [ 4  5]
#  [ 6  7]
#  [ 8  9]
#  [10 11]]

# Transpose (swap rows and columns)
arr_transposed = arr_2d.T
print(arr_transposed)
# [[ 0  4  8]
#  [ 1  5  9]
#  [ 2  6 10]
#  [ 3  7 11]]

# Flatten (convert to 1D array)
arr_flat = arr_2d.flatten()
print(arr_flat)  # [0 1 2 3 4 5 6 7 8 9 10 11]

# In data analysis context
monthly_sales = np.array([10200, 11500, 12800, 11300, 13200, 14100, 
                         13400, 12900, 15200, 16400, 17100, 18500])
# Reshape to quarters (4 rows) by months per quarter (3 columns)
quarterly_sales = monthly_sales.reshape(4, 3)
```

#### 7. Aggregation Functions

**Definition:**
Aggregation functions in NumPy perform calculations that reduce an array to a scalar value or reduce the dimensionality of an array by applying operations along specified axes.

**Explanation:**
NumPy provides a variety of aggregation functions for statistical analysis, including functions for calculating means, sums, minimums, maximums, variances, and more. These functions can operate on entire arrays or along specified axes, making them flexible for different analytical needs. They are essential tools for summarizing and understanding data patterns.

**Example:**
```python
import numpy as np

# Create a 2D array
data = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])

# Aggregation over the entire array
total_sum = np.sum(data)          # 45
mean_value = np.mean(data)        # 5.0
min_value = np.min(data)          # 1
max_value = np.max(data)          # 9
standard_dev = np.std(data)       # 2.58...
variance = np.var(data)           # 6.67...

# Aggregation along axes
row_sums = np.sum(data, axis=1)    # [6, 15, 24] (sum of each row)
col_means = np.mean(data, axis=0)  # [4., 5., 6.] (mean of each column)
col_mins = np.min(data, axis=0)    # [1, 2, 3] (min of each column)
row_maxs = np.max(data, axis=1)    # [3, 6, 9] (max of each row)

# Other useful aggregations
median_value = np.median(data)     # 5.0
percentile_75 = np.percentile(data, 75)  # 7.0
any_true = np.any(data > 5)        # True (any value > 5?)
all_true = np.all(data < 10)       # True (all values < 10?)

# In data analysis context
daily_temperatures = np.array([
    [23.1, 25.3, 24.8, 26.3, 25.2],  # City 1
    [22.5, 23.8, 24.2, 23.9, 22.7],  # City 2
    [27.3, 28.1, 27.5, 26.9, 28.2]   # City 3
])

city_avg_temps = np.mean(daily_temperatures, axis=1)  # Average temp per city
day_avg_temps = np.mean(daily_temperatures, axis=0)   # Average temp per day
temp_range = np.ptp(daily_temperatures, axis=1)       # Temperature range per city
```

#### 8. Linear Algebra Operations

**Definition:**
Linear algebra operations in NumPy perform matrix and vector calculations essential for many scientific computing and machine learning applications.

**Explanation:**
NumPy provides a comprehensive set of functions for linear algebra operations, such as matrix multiplication, determinant calculation, eigenvalue computation, and solving linear systems. These operations are optimized for performance and are the foundation for many advanced data analysis techniques, including dimensionality reduction, regression, and machine learning algorithms.

**Example:**
```python
import numpy as np

# Create matrices
A = np.array([[1, 2], [3, 4]])
B = np.array([[5, 6], [7, 8]])

# Matrix multiplication
C1 = np.dot(A, B)          # [[19, 22], [43, 50]]
C2 = A @ B                 # Same as dot (Python 3.5+)

# Matrix transposition
A_T = A.T                  # [[1, 3], [2, 4]]

# Determinant
det_A = np.linalg.det(A)   # -2.0

# Matrix inverse
A_inv = np.linalg.inv(A)   # [[-2., 1.], [1.5, -0.5]]

# Eigenvalues and eigenvectors
eigenvalues, eigenvectors = np.linalg.eig(A)

# Solving linear equations: Ax = b
b = np.array([1, 2])
x = np.linalg.solve(A, b)  # [-1.,  1.]

# Singular Value Decomposition (SVD)
U, S, Vt = np.linalg.svd(A)

# In data analysis context
# Linear regression using linear algebra
X = np.array([[1, 1], [1, 2], [1, 3], [1, 4], [1, 5]])  # Design matrix with intercept
y = np.array([2, 4, 5, 4, 6])  # Target values
# Calculate coefficients: (X^T X)^(-1) X^T y
beta = np.linalg.inv(X.T @ X) @ X.T @ y
print(f"Intercept: {beta[0]}, Slope: {beta[1]}")
```

### Matplotlib

#### 1. Figure

**Definition:**
A Figure in Matplotlib is the top-level container that holds all plot elements, including one or more Axes (subplots), titles, legends, and other visual elements.

**Explanation:**
The Figure is the overall window or page on which everything is drawn. It serves as a container for all the visual elements of a plot. Figures can be created explicitly using `plt.figure()` or implicitly when creating plots with functions like `plt.plot()`. Understanding the Figure concept is essential for controlling the overall appearance and layout of visualizations.

**Example:**
```python
import matplotlib.pyplot as plt
import numpy as np

# Create a figure with a specific size (width, height) in inches
fig = plt.figure(figsize=(10, 6))

# Add a subplot to the figure
ax = fig.add_subplot(111)  # 1 row, 1 column, 1st plot

# Plot data on the axes
x = np.linspace(0, 10, 100)
ax.plot(x, np.sin(x))

# Add a title to the figure
fig.suptitle('A Simple Sine Wave', fontsize=16)

# Adjust layout
fig.tight_layout(pad=2.0)  # Add padding around subplots

# Save the figure to a file
fig.savefig('sine_wave.png', dpi=300)

# Display the figure
plt.show()

# In data analysis context
# Create a figure for a scientific publication
fig = plt.figure(figsize=(8, 6), facecolor='white')
# The rest of the code would add plots, annotations, etc.
```

#### 2. Axes

**Definition:**
An Axes in Matplotlib is an area where data can be plotted, and it contains two or three axis objects that provide tick marks and labels.

**Explanation:**
The Axes is the primary object for creating plots in Matplotlib. It's a region of the Figure with its own coordinate system where data points are plotted. Each Axes can have properties such as a title, axis labels, and a specific range for each axis. A Figure can contain multiple Axes objects, allowing for the creation of subplots with different types of visualizations.

**Example:**
```python
import matplotlib.pyplot as plt
import numpy as np

# Create a figure and axes
fig, ax = plt.subplots(figsize=(8, 6))

# Plot data on the axes
x = np.linspace(0, 10, 100)
ax.plot(x, np.sin(x), label='Sine')
ax.plot(x, np.cos(x), label='Cosine')

# Customize the axes
ax.set_title('Sine and Cosine Waves')
ax.set_xlabel('x')
ax.set_ylabel('y')
ax.set_xlim(0, 10)
ax.set_ylim(-1.5, 1.5)
ax.grid(True)
ax.legend()

# Add text to the axes
ax.text(5, 0.5, 'Important point', 
        horizontalalignment='center',
        verticalalignment='center',
        bbox=dict(facecolor='white', alpha=0.7))

# Make the axes look better
ax.spines['right'].set_visible(False)
ax.spines['top'].set_visible(False)

plt.show()

# In data analysis context
# Create axes for a specific type of plot
fig, ax = plt.subplots(figsize=(10, 6))
monthly_data = np.random.normal(loc=100, scale=15, size=12)
months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
ax.bar(months, monthly_data)
ax.set_title('Monthly Sales Data')
ax.set_xlabel('Month')
ax.set_ylabel('Sales (thousands)')
```

#### 3. Plots

**Definition:**
Plots in Matplotlib are visual representations of data, created using specific functions like plot(), scatter(), bar(), etc., which display data in different styles on an Axes object.

**Explanation:**
Matplotlib offers numerous plot types to visualize different kinds of data and relationships. Each plot type has its own function and set of parameters to customize its appearance. Common plot types include line plots, scatter plots, bar charts, histograms, and pie charts. Choosing the appropriate plot type is crucial for effectively communicating the patterns and insights in your data.

**Example:**
```python
import matplotlib.pyplot as plt
import numpy as np

# Generate some data
x = np.linspace(0, 10, 30)
y1 = np.sin(x)
y2 = np.cos(x)
categories = ['A', 'B', 'C', 'D', 'E']
values = [25, 32, 15, 40, 28]
data = np.random.randn(1000)

# Create a figure with multiple subplots for different plot types
fig, axes = plt.subplots(2, 3, figsize=(15, 8))

# Line plot
axes[0, 0].plot(x, y1, 'b-', linewidth=2, label='Sine')
axes[0, 0].plot(x, y2, 'r--', linewidth=2, label='Cosine')
axes[0, 0].set_title('Line Plot')
axes[0, 0].legend()

# Scatter plot
axes[0, 1].scatter(x, y1, c=y2, cmap='viridis', s=100*np.abs(y2))
axes[0, 1].set_title('Scatter Plot')

# Bar chart
axes[0, 2].bar(categories, values, color='skyblue')
axes[0, 2].set_title('Bar Chart')

# Histogram
axes[1, 0].hist(data, bins=30, alpha=0.7, color='green')
axes[1, 0].set_title('Histogram')

# Fill between
axes[1, 1].fill_between(x, y1, y2, where=(y1 > y2), 
                       color='skyblue', alpha=0.5, label='y1 > y2')
axes[1, 1].fill_between(x, y1, y2, where=(y1 <= y2), 
                       color='salmon', alpha=0.5, label='y1 <= y2')
axes[1, 1].set_title('Fill Between')
axes[1, 1].legend()

# Pie chart
axes[1, 2].pie(values, labels=categories, autopct='%1.1f%%', 
              shadow=True, startangle=90)
axes[1, 2].set_title('Pie Chart')

plt.tight_layout()
plt.show()

# In data analysis context
# Temperature data visualization
temperatures = np.array([23.1, 24.5, 25.3, 24.8, 25.2, 26.1, 23.8, 25.9, 26.8])
days = np.arange(1, len(temperatures) + 1)

fig, ax = plt.subplots(figsize=(10, 6))
ax.plot(days, temperatures, 'o-', color='darkred', linewidth=2, markersize=8)
ax.axhline(y=np.mean(temperatures), color='blue', linestyle='--', 
          label=f'Mean: {np.mean(temperatures):.1f}°C')
ax.fill_between(days, temperatures, np.min(temperatures), alpha=0.2, color='gray')
ax.set_title('Daily Temperature Readings')
ax.set_xlabel('Day')
ax.set_ylabel('Temperature (°C)')
ax.grid(True, alpha=0.3)
ax.legend()
```

#### 4. Subplots

**Definition:**
Subplots in Matplotlib are multiple Axes objects organized in a grid layout within a single Figure, allowing for the display of multiple plots side by side.

**Explanation:**
Subplots are useful for comparing different datasets or showing different views of the same data. They allow for organized presentation of related visualizations within a single figure. Matplotlib provides several ways to create subplots, including `plt.subplots()`, `plt.subplot()`, and `GridSpec`. Understanding how to create and manage subplots is essential for creating complex, multi-panel visualizations.

**Example:**
```python
import matplotlib.pyplot as plt
import numpy as np

# Generate data
x = np.linspace(0, 10, 100)
y1 = np.sin(x)
y2 = np.exp(-x/2) * np.sin(2*x)
y3 = x**2/10

# Method 1: Using plt.subplots() - creates a grid of subplots
fig, axes = plt.subplots(2, 2, figsize=(10, 8))
axes[0, 0].plot(x, y1)
axes[0, 0].set_title('Sine Wave')
axes[0, 1].plot(x, y2)
axes[0, 1].set_title('Damped Sine Wave')
axes[1, 0].plot(x, y3)
axes[1, 0].set_title('Quadratic Function')
# Leave the last subplot empty or use it for a legend/summary
axes[1, 1].axis('off')
fig.suptitle('Multiple Subplots Example', fontsize=16)

# Method 2: Using plt.subplot() - create subplots one at a time
plt.figure(figsize=(10, 8))

plt.subplot(2, 2, 1)  # 2 rows, 2 columns, 1st subplot
plt.plot(x, y1)
plt.title('Sine Wave')

plt.subplot(2, 2, 2)  # 2 rows, 2 columns, 2nd subplot
plt.plot(x, y2)
plt.title('Damped Sine Wave')

plt.subplot(2, 2, 3)  # 2 rows, 2 columns, 3rd subplot
plt.plot(x, y3)
plt.title('Quadratic Function')

plt.tight_layout()

# Method 3: Using GridSpec for more complex layouts
from matplotlib.gridspec import GridSpec

fig = plt.figure(figsize=(10, 8))
gs = GridSpec(2, 3, figure=fig)

ax1 = fig.add_subplot(gs[0, :])  # First row, all columns
ax2 = fig.add_subplot(gs[1, 0])  # Second row, first column
ax3 = fig.add_subplot(gs[1, 1:])  # Second row, second and third columns

ax1.plot(x, y1)
ax1.set_title('Top Row - Full Width')
ax2.plot(x, y2)
ax2.set_title('Bottom Left')
ax3.plot(x, y3)
ax3.set_title('Bottom Right - Double Width')

plt.tight_layout()

# In data analysis context
# Creating subplots for comparing different aspects of the same dataset
rainfall = np.random.normal(loc=50, scale=20, size=12)
temperature = np.random.normal(loc=20, scale=8, size=12)
humidity = np.random.normal(loc=60, scale=15, size=12)
months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']

fig, axes = plt.subplots(3, 1, figsize=(10, 10), sharex=True)  # Share x-axis

axes[0].bar(months, rainfall, color='blue', alpha=0.7)
axes[0].set_title('Monthly Rainfall (mm)')
axes[0].set_ylabel('Rainfall (mm)')
axes[0].grid(True, alpha=0.3)

axes[1].plot(months, temperature, 'ro-', linewidth=2)
axes[1].set_title('Monthly Temperature (°C)')
axes[1].set_ylabel('Temperature (°C)')
axes[1].grid(True, alpha=0.3)

axes[2].fill_between(months, humidity, alpha=0.5, color='green')
axes[2].set_title('Monthly Humidity (%)')
axes[2].set_xlabel('Month')
axes[2].set_ylabel('Humidity (%)')
axes[2].grid(True, alpha=0.3)

fig.suptitle('Climate Data Analysis', fontsize=16)
fig.tight_layout(rect=[0, 0, 1, 0.95])  # Make room for the figure title

#### 5. Customization

**Definition:**
Customization in Matplotlib refers to modifying the appearance and style of plots, including colors, markers, line styles, fonts, labels, and other visual elements to enhance readability and aesthetic appeal.

**Explanation:**
Matplotlib provides extensive customization options to control virtually every aspect of a visualization. This includes setting colors, controlling transparency, adjusting line widths and styles, modifying axis properties, adding annotations, and much more. Effective customization is essential for creating clear, professional-looking visualizations that effectively communicate insights from your data.

**Example:**
```python
import matplotlib.pyplot as plt
import numpy as np

# Generate data
x = np.linspace(0, 10, 100)
y1 = np.sin(x)
y2 = np.cos(x)

# Create figure and axes
fig, ax = plt.subplots(figsize=(10, 6))

# Basic plot with customization
ax.plot(x, y1, color='#FF5733', linestyle='-', linewidth=2.5, 
       marker='o', markevery=10, markersize=8, label='Sine')
ax.plot(x, y2, color='#3498DB', linestyle='--', linewidth=2, 
       marker='^', markevery=10, markersize=8, label='Cosine')

# Customize the plot title and labels
ax.set_title('Sine and Cosine Waves', fontsize=18, fontweight='bold')
ax.set_xlabel('Angle (radians)', fontsize=14, labelpad=10)
ax.set_ylabel('Amplitude', fontsize=14, labelpad=10)

# Customize the axis properties
ax.set_xlim(0, 10)
ax.set_ylim(-1.5, 1.5)
ax.tick_params(axis='both', which='major', labelsize=12, direction='out', length=5)
ax.grid(True, linestyle='--', alpha=0.7)

# Add a legend
ax.legend(fontsize=12, loc='best', frameon=True, framealpha=0.8, 
         facecolor='white', edgecolor='gray')

# Customize the spines
ax.spines['right'].set_visible(False)
ax.spines['top'].set_visible(False)
ax.spines['left'].set_linewidth(1.5)
ax.spines['bottom'].set_linewidth(1.5)

# Add annotations
ax.annotate('Maximum', xy=(np.pi/2, 1), xytext=(np.pi/2, 1.3),
           arrowprops=dict(facecolor='black', shrink=0.05, width=1.5),
           fontsize=12, ha='center')
ax.annotate('Minimum', xy=(3*np.pi/2, -1), xytext=(3*np.pi/2, -1.3),
           arrowprops=dict(facecolor='black', shrink=0.05, width=1.5),
           fontsize=12, ha='center')

# Add a text box
props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)
textstr = '\n'.join((
    r'$f_1(x)=\sin(x),
    r'$f_2(x)=\cos(x),
    r'$x \in [0, 10]))
ax.text(0.05, 0.95, textstr, transform=ax.transAxes, fontsize=12,
       verticalalignment='top', bbox=props)

# Change the figure background color
fig.patch.set_facecolor('#F8F9F9')
ax.set_facecolor('#EAEDED')

# Add a colorbar (even though it's not needed for this plot, as an example)
from matplotlib.cm import ScalarMappable
from matplotlib.colors import Normalize
sm = ScalarMappable(norm=Normalize(0, 10), cmap='viridis')
sm.set_array([])
cbar = fig.colorbar(sm, ax=ax, label='Colorbar Example')

plt.tight_layout()

# In data analysis context
# Creating a custom visualization of monthly sales data with target markers
months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
sales = np.array([12.5, 15.3, 18.2, 16.4, 19.8, 22.3, 20.5, 18.7, 24.1, 26.5, 25.2, 28.4])
targets = np.array([15, 15, 18, 18, 20, 20, 20, 20, 22, 22, 25, 25])

fig, ax = plt.subplots(figsize=(12, 7))

# Create a color gradient based on whether sales met targets
colors = ['green' if s >= t else 'red' for s, t in zip(sales, targets)]
bar_plot = ax.bar(months, sales, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)

# Add target line
ax.plot(months, targets, 'o-', color='blue', linewidth=2.5, markersize=8, label='Monthly Target')

# Add data labels
for i, (m, s) in enumerate(zip(months, sales)):
    ax.text(i, s + 0.5, f'{s:.1f}', ha='center', va='bottom', fontsize=10, fontweight='bold')

# Customize chart elements
ax.set_title('Monthly Sales Performance vs. Targets', fontsize=18, pad=20)
ax.set_xlabel('Month', fontsize=14, labelpad=10)
ax.set_ylabel('Sales (millions $)', fontsize=14, labelpad=10)
ax.set_ylim(0, max(sales.max(), targets.max()) * 1.2)
ax.grid(axis='y', linestyle='--', alpha=0.7)

# Add legend and annotations
ax.legend(fontsize=12, loc='upper left')

# Annotate key insights
ax.annotate('Year-end surge', xy=('Dec', 28.4), xytext=('Oct', 27),
           arrowprops=dict(facecolor='black', shrink=0.05, width=1),
           fontsize=12)

# Add summary text box
met_targets = sum(s >= t for s, t in zip(sales, targets))
textstr = '\n'.join((
    f'Met Targets: {met_targets}/12 months',
    f'Best Month: {months[np.argmax(sales)]} (${sales.max():.1f}M)',
    f'Sales Growth: {((sales[-1] - sales[0]) / sales[0] * 100):.1f}%'))
ax.text(0.02, 0.95, textstr, transform=ax.transAxes, fontsize=12,
       verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.9))

# Custom styling for a professional look
plt.xticks(fontsize=12)
plt.yticks(fontsize=12)
for spine in ax.spines.values():
    spine.set_linewidth(1.5)

fig.tight_layout()
```

#### 6. Saving Figures

**Definition:**
Saving figures in Matplotlib involves exporting visualizations to various file formats for use in reports, presentations, websites, or publications.

**Explanation:**
Matplotlib supports saving figures in a wide range of formats, including PNG, PDF, SVG, JPEG, and more. When saving figures, you can control aspects such as resolution (DPI), transparency, and size. Proper figure saving ensures that your visualizations maintain their quality and appearance when shared or published in different media.

**Example:**
```python
import matplotlib.pyplot as plt
import numpy as np

# Create a simple figure
x = np.linspace(0, 10, 100)
y = np.sin(x)

plt.figure(figsize=(8, 6))
plt.plot(x, y, 'b-', linewidth=2)
plt.title('Sine Wave')
plt.xlabel('x')
plt.ylabel('sin(x)')
plt.grid(True)

# Method 1: Save using plt.savefig()
plt.savefig('sine_wave.png')  # Default format and settings

# Method 2: Save with specific parameters
plt.savefig('sine_wave_high_res.png', 
           dpi=300,              # Higher resolution
           bbox_inches='tight',  # Trim whitespace around the figure
           transparent=True)     # Transparent background

# Method 3: Save in different formats
plt.savefig('sine_wave.pdf')  # PDF format
plt.savefig('sine_wave.svg')  # SVG format (scalable)
plt.savefig('sine_wave.jpg', quality=95)  # JPEG format with quality setting

# Method 4: Save from a Figure object
fig, ax = plt.subplots(figsize=(10, 6))
ax.plot(x, y, 'r-')
ax.set_title('Another Sine Wave')
fig.savefig('another_sine_wave.png', dpi=200)

# In data analysis context
# Creating and saving a figure for a scientific publication
fig, ax = plt.subplots(figsize=(8, 6))
ax.plot(x, y, 'k-', linewidth=1.5)
ax.set_title('Sine Function')
ax.set_xlabel('x')
ax.set_ylabel('y')
ax.grid(True, linestyle='--', alpha=0.7)

# Save in various formats for different uses
# For web use
fig.savefig('sine_web.png', dpi=72, optimize=True, bbox_inches='tight')

# For print publication
fig.savefig('sine_print.tiff', dpi=300, bbox_inches='tight')

# For presentation
fig.savefig('sine_presentation.png', dpi=150, bbox_inches='tight')

# For vector graphics (scalable)
fig.savefig('sine_vector.svg', bbox_inches='tight')

# For inclusion in LaTeX document
fig.savefig('sine_latex.pdf', bbox_inches='tight')
```

### Statistical Analysis

#### 1. Mean

**Definition:**
Mean (or average) is a measure of central tendency calculated by summing all values in a dataset and dividing by the number of values.

**Explanation:**
The mean is one of the most common statistical measures used to summarize data. It represents the "center" of a distribution and is sensitive to all values in the dataset, including outliers. NumPy provides efficient functions for calculating means across entire arrays or along specified axes. Understanding the mean is fundamental for data analysis and forms the basis for many statistical techniques.

**Example:**
```python
import numpy as np
import matplotlib.pyplot as plt

# Create sample data
data = np.array([15, 23, 18, 25, 30, 19, 22, 27, 20, 21])

# Calculate mean
mean_value = np.mean(data)  # 22.0

# For 2D arrays, calculate mean along axes
data_2d = np.array([
    [10, 15, 20],
    [25, 30, 35],
    [40, 45, 50]
])
row_means = np.mean(data_2d, axis=1)  # [15, 30, 45]
col_means = np.mean(data_2d, axis=0)  # [25, 30, 35]

# Visualize data with mean
plt.figure(figsize=(10, 6))
plt.bar(range(len(data)), data, alpha=0.7, color='skyblue')
plt.axhline(y=mean_value, color='red', linestyle='--', 
           label=f'Mean: {mean_value}')
plt.xlabel('Data Point')
plt.ylabel('Value')
plt.title('Data Values with Mean')
plt.legend()
plt.grid(True, alpha=0.3)

# In data analysis context
# Analyzing temperature readings with mean
temperatures = np.array([23.1, 24.5, 25.3, 24.8, 25.2, 26.1, 23.8, 25.9, 26.8])
mean_temp = np.mean(temperatures)  # 25.06

print(f"Mean temperature: {mean_temp:.2f}°C")
print(f"Values above mean: {np.sum(temperatures > mean_temp)}")
print(f"Values below mean: {np.sum(temperatures < mean_temp)}")

# Calculate deviation from mean
deviations = temperatures - mean_temp
squared_deviations = deviations ** 2
```

#### 2. Variance

**Definition:**
Variance is a measure of the spread or dispersion of a dataset, calculated as the average of squared differences from the mean.

**Explanation:**
Variance quantifies how much the individual data points differ from the mean, with higher values indicating greater dispersion. It's calculated by taking the squared differences between each value and the mean, and then averaging those squared differences. Understanding variance is crucial for assessing the variability and consistency in your data, and it forms the basis for many statistical analyses and techniques.

**Example:**
```python
import numpy as np
import matplotlib.pyplot as plt

# Create sample datasets with different variances
data1 = np.array([10, 11, 9, 12, 10, 11, 10, 9, 11, 12])  # Low variance
data2 = np.array([5, 10, 15, 20, 5, 15, 10, 20, 5, 15])   # High variance

# Calculate means and variances
mean1 = np.mean(data1)  # 10.5
var1 = np.var(data1)    # 1.05
std1 = np.std(data1)    # 1.02 (standard deviation = sqrt(variance))

mean2 = np.mean(data2)  # 12.0
var2 = np.var(data2)    # 31.11
std2 = np.std(data2)    # 5.58

# Visualize the data
plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
plt.bar(range(len(data1)), data1, alpha=0.7, color='skyblue')
plt.axhline(y=mean1, color='red', linestyle='--', 
           label=f'Mean: {mean1:.1f}')
plt.title(f'Low Variance Data (Var: {var1:.2f})')
plt.ylim(0, 25)
plt.legend()

plt.subplot(1, 2, 2)
plt.bar(range(len(data2)), data2, alpha=0.7, color='lightgreen')
plt.axhline(y=mean2, color='red', linestyle='--', 
           label=f'Mean: {mean2:.1f}')
plt.title(f'High Variance Data (Var: {var2:.2f})')
plt.ylim(0, 25)
plt.legend()

plt.tight_layout()

# Manual calculation of variance (for understanding)
def manual_variance(data):
    mean = np.mean(data)
    squared_diff = (data - mean) ** 2
    variance = np.sum(squared_diff) / len(data)
    return variance

print(f"NumPy variance: {var1:.2f}")
print(f"Manual variance: {manual_variance(data1):.2f}")

# In data analysis context
# Analyzing monthly sales data
monthly_sales = np.array([120, 135, 128, 142, 131, 155, 148, 136, 162, 158, 145, 170])
sales_mean = np.mean(monthly_sales)
sales_var = np.var(monthly_sales)
sales_std = np.std(monthly_sales)

print(f"Average monthly sales: ${sales_mean:.2f}")
print(f"Variance: ${sales_var:.2f}")
print(f"Standard deviation: ${sales_std:.2f}")

# Coefficient of variation (standardized measure of dispersion)
cv = (sales_std / sales_mean) * 100
print(f"Coefficient of variation: {cv:.2f}%")

# Identifying months with unusually high or low sales (beyond 1 std dev)
unusual_months = np.abs(monthly_sales - sales_mean) > sales_std
print(f"Number of unusual months: {np.sum(unusual_months)}")
```

#### 3. Correlation

**Definition:**
Correlation is a statistical measure that quantifies the strength and direction of the linear relationship between two variables, with values ranging from -1 (perfect negative correlation) to +1 (perfect positive correlation).

**Explanation:**
Correlation coefficients, such as Pearson's r, indicate how strongly two variables are related. A value close to +1 indicates a strong positive relationship (as one variable increases, the other also increases), while a value close to -1 indicates a strong negative relationship (as one variable increases, the other decreases). A value near 0 suggests little to no linear relationship. Correlation analysis is essential for identifying patterns and relationships in your data.

**Example:**
```python
import numpy as np
import matplotlib.pyplot as plt

# Generate data with different correlation patterns
np.random.seed(42)  # For reproducibility

# Positive correlation
x_pos = np.random.normal(0, 1, 100)
y_pos = x_pos * 0.8 + np.random.normal(0, 0.5, 100)
corr_pos = np.corrcoef(x_pos, y_pos)[0, 1]  # ~0.85

# Negative correlation
x_neg = np.random.normal(0, 1, 100)
y_neg = -x_neg * 0.8 + np.random.normal(0, 0.5, 100)
corr_neg = np.corrcoef(x_neg, y_neg)[0, 1]  # ~-0.85

# No correlation
x_no = np.random.normal(0, 1, 100)
y_no = np.random.normal(0, 1, 100)
corr_no = np.corrcoef(x_no, y_no)[0, 1]  # ~0

# Visualize the correlations
plt.figure(figsize=(15, 5))

plt.subplot(1, 3, 1)
plt.scatter(x_pos, y_pos, alpha=0.7)
plt.title(f'Positive Correlation (r = {corr_pos:.2f})')
plt.grid(True, alpha=0.3)

plt.subplot(1, 3, 2)
plt.scatter(x_neg, y_neg, alpha=0.7)
plt.title(f'Negative Correlation (r = {corr_neg:.2f})')
plt.grid(True, alpha=0.3)

plt.subplot(1, 3, 3)
plt.scatter(x_no, y_no, alpha=0.7)
plt.title(f'No Correlation (r = {corr_no:.2f})')
plt.grid(True, alpha=0.3)

plt.tight_layout()

# Calculate correlation matrix for multiple variables
data = np.vstack([x_pos, y_pos, x_neg, y_neg]).T
corr_matrix = np.corrcoef(data, rowvar=False)
print("Correlation Matrix:")
print(corr_matrix)

# Visualize correlation matrix
plt.figure(figsize=(8, 6))
plt.imshow(corr_matrix, cmap='coolwarm', vmin=-1, vmax=1)
plt.colorbar(label='Correlation Coefficient')
plt.title('Correlation Matrix')
plt.xticks(np.arange(4), ['x_pos', 'y_pos', 'x_neg', 'y_neg'])
plt.yticks(np.arange(4), ['x_pos', 'y_pos', 'x_neg', 'y_neg'])

for i in range(4):
    for j in range(4):
        plt.text(j, i, f'{corr_matrix[i, j]:.2f}', 
                ha='center', va='center', color='white' if abs(corr_matrix[i, j]) > 0.5 else 'black')

# In data analysis context
# Analyzing the relationship between advertising spending and sales
advertising = np.array([23, 26, 30, 34, 43, 48, 52, 57, 58])  # in thousands of dollars
sales = np.array([651, 762, 856, 1063, 1190, 1298, 1421, 1440, 1518])  # in units sold

# Calculate the correlation coefficient
correlation = np.corrcoef(advertising, sales)[0, 1]  # Should be close to 1
print(f"Correlation between advertising and sales: {correlation:.4f}")

# Visualize the relationship
plt.figure(figsize=(10, 6))
plt.scatter(advertising, sales, s=100, alpha=0.7, color='blue')
plt.title(f'Relationship between Advertising and Sales (r = {correlation:.4f})')
plt.xlabel('Advertising Spend (thousands $)')
plt.ylabel('Units Sold')
plt.grid(True, alpha=0.3)

# Add a trend line
z = np.polyfit(advertising, sales, 1)
p = np.poly1d(z)
plt.plot(advertising, p(advertising), 'r--', linewidth=2)
```

#### 4. Linear Regression

**Definition:**
Linear regression is a statistical model that examines the linear relationship between a dependent variable (Y) and one or more independent variables (X), finding the best-fitting line through the data points.

**Explanation:**
Linear regression helps us understand how changes in predictor variables relate to changes in the response variable. It models this relationship by fitting a linear equation to the observed data. The key components are the slope (which indicates the rate of change) and the intercept (the baseline value when all predictors are zero). Linear regression is widely used for prediction, forecasting, and understanding variable relationships.

**Example:**
```python
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

# Generate some data with a linear relationship plus noise
np.random.seed(42)
x = np.linspace(0, 10, 50)
y = 2 * x + 1 + np.random.normal(0, 1, 50)  # y = 2x + 1 + noise

# Perform linear regression using NumPy
slope, intercept = np.polyfit(x, y, 1)
print(f"NumPy - Slope: {slope:.4f}, Intercept: {intercept:.4f}")

# Perform linear regression using scipy.stats (provides more statistics)
slope_sp, intercept_sp, r_value, p_value, std_err = stats.linregress(x, y)
print(f"Scipy - Slope: {slope_sp:.4f}, Intercept: {intercept_sp:.4f}")
print(f"R-squared: {r_value**2:.4f}")
print(f"P-value: {p_value:.10f}")
print(f"Standard Error: {std_err:.4f}")

# Predicted values using the linear model
y_pred = slope * x + intercept

# Visualize the data and regression line
plt.figure(figsize=(10, 6))
plt.scatter(x, y, color='blue', alpha=0.7, label='Data Points')
plt.plot(x, y_pred, color='red', linewidth=2, label=f'Regression Line: y = {slope:.2f}x + {intercept:.2f}')
plt.title('Linear Regression Example')
plt.xlabel('X')
plt.ylabel('Y')
plt.legend()
plt.grid(True, alpha=0.3)

# Calculate residuals (the differences between observed and predicted values)
residuals = y - y_pred

# Plot residuals
plt.figure(figsize=(10, 6))
plt.scatter(x, residuals, color='green', alpha=0.7)
plt.axhline(y=0, color='red', linestyle='--')
plt.title('Residual Plot')
plt.xlabel('X')
plt.ylabel('Residuals')
plt.grid(True, alpha=0.3)

# In data analysis context
# Predict house prices based on square footage
square_feet = np.array([1400, 1600, 1700, 1875, 1950, 2150, 2400, 2700, 3000, 3200])
house_prices = np.array([220000, 248000, 260000, 285000, 290000, 330000, 350000, 379000, 400000, 425000])

# Perform linear regression
slope, intercept, r_value, p_value, std_err = stats.linregress(square_feet, house_prices)

# Create prediction function
def predict_price(sf):
    return slope * sf + intercept

# Predict prices for new square footages
new_sf = np.array([1500, 2000, 2500, 3500])
predicted_prices = predict_price(new_sf)

print("\nHouse Price Prediction:")
print(f"Model: Price = {slope:.2f} × Square Feet + {intercept:.2f}")
print(f"R-squared: {r_value**2:.4f}")

for sf, price in zip(new_sf, predicted_prices):
    print(f"{sf} sq ft house: ${price:.2f}")

# Visualize the house price data and regression line
plt.figure(figsize=(10, 6))
plt.scatter(square_feet, house_prices, s=100, alpha=0.7, color='blue', label='Actual Prices')
plt.plot(square_feet, predict_price(square_feet), color='red', linewidth=2, label='Regression Line')
plt.scatter(new_sf, predicted_prices, s=100, color='green', marker='x', label='Predicted Prices')

for sf, price in zip(new_sf, predicted_prices):
    plt.annotate(f'${price/1000:.0f}K', (sf, price), textcoords="offset points", 
                xytext=(0,10), ha='center')

plt.title('House Price vs Square Footage')
plt.xlabel('Square Footage')
plt.ylabel('Price ($)')
plt.legend()
plt.grid(True, alpha=0.3